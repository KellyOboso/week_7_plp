# fairness_audit.ipynb

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from aif360.datasets import CompasDataset
from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric
from aif360.algorithms.preprocessing import Reweighing

# Load dataset
compas = CompasDataset()

# Check protected attribute: race
privileged_groups = [{'race': 1}]  # Caucasian
unprivileged_groups = [{'race': 0}]  # African-American

# Compute bias metrics
metric = BinaryLabelDatasetMetric(compas, 
                                  unprivileged_groups=unprivileged_groups,
                                  privileged_groups=privileged_groups)

print("Mean difference:", metric.mean_difference())
print("Disparate impact ratio:", metric.disparate_impact())

# Visualize
labels = ['Privileged', 'Unprivileged']
counts = [metric.num_instances(privileged=True),
          metric.num_instances(privileged=False)]

plt.bar(labels, counts)
plt.title("Sample counts by group")
plt.show()
